{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import importlib as imp\n",
    "import gc; gc.enable()\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns',1000)\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss as log_loss\n",
    "import json\n",
    "import mylibs.WSDN_FUNC as func\n",
    "%cd e:\\kaggle\\wsdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_datatype(df):\n",
    "    int_cols = list(df.select_dtypes(include=['int']).columns)\n",
    "    for col in int_cols:\n",
    "        if ((np.max(df[col]) <= 127) and(np.min(df[col] >= -128))):\n",
    "            df[col] = df[col].astype(np.int8)\n",
    "        elif ((np.max(df[col]) <= 32767) and(np.min(df[col] >= -32768))):\n",
    "            df[col] = df[col].astype(np.int16)\n",
    "        elif ((np.max(df[col]) <= 2147483647) and(np.min(df[col] >= -2147483648))):\n",
    "            df[col] = df[col].astype(np.int32)\n",
    "        else:\n",
    "            df[col] = df[col].astype(np.int64)\n",
    "\n",
    "def change_datatype_float(df):\n",
    "    float_cols = list(df.select_dtypes(include=['float']).columns)\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].astype(np.float32)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(train_y, scores):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(train_y, scores)\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recalls\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 1, 0.03))\n",
    "    plt.grid(True, linestyle='-.')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc_curve(train_y, scores):\n",
    "    from sklearn.metrics import roc_curve\n",
    "    fpr, tpr, thresholds = roc_curve(train_y, scores)\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 0], [1, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare base data\n",
    "print(\"reading training and submission data...\")\n",
    "train = pd.read_csv(\"train.csv/train.csv\")\n",
    "test = pd.read_csv(\"sample_submission.csv/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"processing transaction data...\")\n",
    "transactions = pd.read_csv('transactions.csv/transactions.csv')\n",
    "date_cols = ['transaction_date', 'membership_expire_date']\n",
    "for col in date_cols:\n",
    "    transactions[col] = pd.to_datetime(transactions[col], format='%Y%m%d')\n",
    "    \n",
    "print(\"----processing transaction counts data...\")\n",
    "transaction_counts = transactions['msno'].value_counts().reset_index()\n",
    "transaction_counts.columns = ['msno','trans_count']\n",
    "train = pd.merge(train, transaction_counts, how='left', on='msno')\n",
    "test = pd.merge(test, transaction_counts, how='left', on='msno')\n",
    "transaction_counts=[]\n",
    "gc.collect()\n",
    "\n",
    "print(\"----processing transaction last record data...\")\n",
    "transaction_last_date = transactions.sort_values(by=['transaction_date'], ascending=[False]).reset_index(drop=True)\n",
    "transaction_last_date = transaction_last_date.drop_duplicates(subset=['msno'], keep='first')\n",
    "transaction_last_date[\"discount\"] = transaction_last_date['plan_list_price'] - transaction_last_date['actual_amount_paid']\n",
    "transaction_last_date['is_discount'] = transaction_last_date.discount.apply(lambda x: 1 if x > 0 else 0)\n",
    "transaction_last_date['amt_per_day'] = transaction_last_date['actual_amount_paid'] / transaction_last_date['payment_plan_days']\n",
    "transaction_last_date['membership_duration'] = transaction_last_date.membership_expire_date - transaction_last_date.transaction_date\n",
    "transaction_last_date['membership_duration'] = transaction_last_date['membership_duration'] / np.timedelta64(1, 'D')\n",
    "transaction_last_date['membership_duration'] = transaction_last_date['membership_duration'].astype(int)\n",
    "transaction_last_date = transaction_last_date.drop(list(transaction_last_date.select_dtypes(include=['datetime64[ns]']).columns), 1)\n",
    "train = pd.merge(train, transaction_last_date, how='left', on='msno')\n",
    "test = pd.merge(test, transaction_last_date, how='left', on='msno')\n",
    "print('----retain transaction_last_date for members.')\n",
    "\n",
    "print(\"----processing transaction last 2 months counts data...\")\n",
    "transaction_last2 = transactions.sort_values(by=['transaction_date'], ascending=[True]).reset_index(drop=True)\n",
    "transaction_last2 = transaction_last2.set_index(\"transaction_date\").truncate(before = '2017-02-01').reset_index()\n",
    "transaction_last2 = pd.DataFrame(transaction_last2['msno'].value_counts().reset_index())\n",
    "transaction_last2.columns = ['msno','trans_count2']\n",
    "train = pd.merge(train, transaction_last2, how='left', on='msno')\n",
    "test = pd.merge(test, transaction_last2, how='left', on='msno')\n",
    "transaction_last2 = []\n",
    "transactions = []\n",
    "gc.collect()\n",
    "print('transaction merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"processing member data...\")\n",
    "members = pd.read_csv('members.csv/members.csv')\n",
    "df_comb = pd.merge(transaction_last_date, members, on='msno', how='inner')\n",
    "df_comb['autorenew_&_not_cancel'] = ((df_comb.is_auto_renew == 1) == (df_comb.is_cancel == 0)).astype(np.int8)\n",
    "df_comb['notAutorenew_&_cancel'] = ((df_comb.is_auto_renew == 0) == (df_comb.is_cancel == 1)).astype(np.int8)\n",
    "drop_cols = list(members.select_dtypes(include=['datetime64[ns]']).columns) + list(transaction_last_date.columns)\n",
    "drop_cols.remove('msno')\n",
    "df_comb = df_comb.drop(drop_cols, 1)\n",
    "train = pd.merge(train, df_comb, how='left', on='msno')\n",
    "test = pd.merge(test, df_comb, how='left', on='msno')\n",
    "print(\"----data clean...\")\n",
    "gender = {'male':1, 'female':2}\n",
    "train['gender'] = train['gender'].map(gender)\n",
    "test['gender'] = test['gender'].map(gender)\n",
    "train_bd_clipped = train[\"bd\"].clip(18, 60)\n",
    "test_bd_clipped = test[\"bd\"].clip(18, 60)\n",
    "train_bd_mean = train_bd_clipped.mean()\n",
    "test_bd_mean = test_bd_clipped.mean()\n",
    "train[\"bd\"] = train[\"bd\"].apply(lambda x: train_bd_mean if x <18 or x >60 else x )\n",
    "test[\"bd\"] = test[\"bd\"].apply(lambda x: test_bd_mean if x <18 or x >60 else x )\n",
    "train_bd_clipped = []\n",
    "test_bd_clipped = []\n",
    "transaction_last_date = []\n",
    "members = []\n",
    "df_comb = []\n",
    "gc.collect()\n",
    "print('members merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"processing logs data...\")\n",
    "df_iter = pd.read_csv('user_logs.csv/user_logs.csv', low_memory=False, iterator=True, chunksize=10000000)\n",
    "last_user_logs = []\n",
    "i = 0 \n",
    "for df in df_iter:\n",
    "    if len(df)>0:\n",
    "        print(df.shape)\n",
    "        p = Pool(cpu_count())\n",
    "        df = p.map(transform_df, np.array_split(df, cpu_count()))   \n",
    "        df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "        df = transform_df2(df)\n",
    "        p.close(); p.join()\n",
    "        last_user_logs.append(df)\n",
    "        print('...', df.shape)\n",
    "        df = []\n",
    "        gc.collect()\n",
    "    i+=1\n",
    "\n",
    "last_user_logs = pd.concat(last_user_logs, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "last_user_logs = transform_df2(last_user_logs)\n",
    "\n",
    "train = pd.merge(train, last_user_logs, how='left', on='msno')\n",
    "test = pd.merge(test, last_user_logs, how='left', on='msno')\n",
    "last_user_logs=[]\n",
    "gc.collect()\n",
    "print('logs merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_iter\n",
    "user_logs = pd.read_csv('user_logs.csv/user_logs.csv', usecols=['msno'])\n",
    "user_logs = pd.DataFrame(user_logs['msno'].value_counts().reset_index())\n",
    "user_logs.columns = ['msno','logs_count']\n",
    "train = pd.merge(train, user_logs, how='left', on='msno')\n",
    "test = pd.merge(test, user_logs, how='left', on='msno')\n",
    "user_logs = []\n",
    "gc.collect()\n",
    "print('user logs count merged.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extra features\n",
    "print(\"processing extra features...\")\n",
    "extra_features = pd.read_csv(\"extra_features.csv\")\n",
    "exclude_mean_cols = [col for col in extra_features.columns if not col.endswith(\"mean\")]\n",
    "extra_features = extra_features[exclude_mean_cols]\n",
    "train = pd.merge(train, extra_features, how='left', on='msno')\n",
    "test = pd.merge(test, extra_features, how='left', on='msno')\n",
    "extra_features3 = pd.read_csv(\"extra_features3.csv\")\n",
    "train = pd.merge(train, extra_features3, how='left', on='msno')\n",
    "test = pd.merge(test, extra_features3, how='left', on='msno')\n",
    "extra_features4 = pd.read_csv(\"extra_features4.csv\")\n",
    "train = pd.merge(train, extra_features4, how='left', on='msno')\n",
    "test = pd.merge(test, extra_features4, how='left', on='msno')\n",
    "extra_features5 = pd.read_csv(\"extra_features5.csv\")\n",
    "train = pd.merge(train, extra_features5, how='left', on='msno')\n",
    "test = pd.merge(test, extra_features5, how='left', on='msno')\n",
    "del extra_features\n",
    "del extra_features3\n",
    "del extra_features4\n",
    "del extra_features5\n",
    "gc.collect()\n",
    "print(\"extra features merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_features.csv', index=False)\n",
    "test.to_csv('test_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training preparation\n",
    "train = pd.read_csv(\"train_features.csv\")\n",
    "test = pd.read_csv(\"test_features.csv\")\n",
    "# missing values\n",
    "data_pack = [train, test]\n",
    "for i, data in enumerate(data_pack):\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    mean_cols = ['payment_plan_days', 'plan_list_price', 'actual_amount_paid', 'discount', 'amt_per_day', 'membership_duration', 'bd'] \n",
    "    mode_cols = ['payment_method_id', 'is_auto_renew', 'is_cancel', 'is_discount', 'city', 'gender', 'registered_via', 'registration_init_time', 'autorenew_&_not_cancel', 'notAutorenew_&_cancel', 'date']\n",
    "    other_cols = [col for col in data.columns if col not in mean_cols if col not in mode_cols]\n",
    "    data[mean_cols] = data[mean_cols].fillna(data[mean_cols].mean())\n",
    "    data[mode_cols] = data[mode_cols].fillna(data[mode_cols].mode().iloc[0])\n",
    "    data[other_cols]= data[other_cols].fillna(0)\n",
    "    data_pack[i] = data\n",
    "train, test = data_pack\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_datatype(train);change_datatype(test)\n",
    "change_datatype_float(train);change_datatype_float(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training features\n",
    "cols = [col for col in train.columns if col not in ['is_churn','msno']]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train[cols + [\"is_churn\"]].astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClfModel(object):\n",
    "    feature_name_prefix = \"%s_feature_%d\"\n",
    "    feature_index = 0\n",
    "\n",
    "class XgbModel(ClfModel):    \n",
    "    def __init__(self, params, kfold=None, ROUND=150, SEED=0):\n",
    "        self.model = None\n",
    "        self.new_feature_cols = []\n",
    "        self.xgb_params = params\n",
    "        self.kfold = kfold\n",
    "        self.ROUND = ROUND\n",
    "        self.SEED = SEED\n",
    "    \n",
    "    def train_pred(self, train_x, train_y, test_x, test_split_ratio = 0.3, valid_x = None, valid_y = None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.new_feature_cols = []\n",
    "        self.valid_x = valid_x\n",
    "        self.valid_y = valid_y\n",
    "        if self.kfold is not None:\n",
    "            return self.__train_use_kfold(self.kfold)\n",
    "        else:\n",
    "            return self.__train_use_splitratio(test_split_ratio)\n",
    "    \n",
    "    def __train_use_kfold(self, kfold):\n",
    "        training_prediction = np.zeros((self.train_x.shape[0],))\n",
    "        test_prediction = np.empty((kfold.n_folds, self.test_x.shape[0]))\n",
    "        for i, (train_index, test_index) in enumerate(kfold):\n",
    "            print(\"xgb training round %d\" % i)\n",
    "            train_data_x = self.train_x[train_index]\n",
    "            train_data_y = self.train_y[train_index]\n",
    "            training_test_data_x = self.train_x[test_index]\n",
    "            training_test_data_y = self.train_y[test_index]\n",
    "            eval_list = [(xgb.DMatrix(train_data_x, train_data_y), 'train'), (xgb.DMatrix(training_test_data_x, training_test_data_y), 'validation')]\n",
    "            model = xgb.train(self.xgb_params, xgb.DMatrix(train_data_x, train_data_y), self.ROUND, evals=eval_list, maximize=False, verbose_eval=50, early_stopping_rounds=50)\n",
    "            training_prediction[test_index] = model.predict(xgb.DMatrix(training_test_data_x), ntree_limit=model.best_ntree_limit)\n",
    "            test_prediction[i, :] = model.predict(xgb.DMatrix(self.test_x), ntree_limit=model.best_ntree_limit)\n",
    "            del model\n",
    "            gc.collect()\n",
    "        new_feature = ClfModel.feature_name_prefix % (\"xgb\", ClfModel.feature_index)\n",
    "        ClfModel.feature_index += 1\n",
    "        training_prediction = pd.DataFrame(training_prediction.clip(0.0000001, 0.999999), columns=[new_feature])\n",
    "        test_prediction = pd.DataFrame(test_prediction.clip(0.0000001, 0.999999).mean(axis=0).reshape(-1, 1), columns=[new_feature])\n",
    "        self.new_feature_cols += [new_feature]\n",
    "        print(self.new_feature_cols)\n",
    "        return training_prediction, test_prediction, self.new_feature_cols, [1]\n",
    "    \n",
    "    def __train_use_splitratio(self, ratio):\n",
    "        print(\"stacking training.\")\n",
    "        if ratio > 0:\n",
    "            train_x, valid_x, train_y, valid_y = model_selection.train_test_split(self.train_x, self.train_y, test_size=ratio, random_state=self.SEED)\n",
    "            eval_list = [(xgb.DMatrix(train_x, train_y), 'train'), (xgb.DMatrix(valid_x, valid_y), 'validation')]\n",
    "        else:\n",
    "            train_x = self.train_x\n",
    "            train_y = self.train_y\n",
    "            if self.valid_x is None or self.valid_y is None:\n",
    "                valid_x = self.train_x\n",
    "                valid_y = self.train_y\n",
    "            else:\n",
    "                valid_x = self.valid_x\n",
    "                valid_y = self.valid_y\n",
    "            eval_list = [(xgb.DMatrix(train_x, train_y), 'train')]\n",
    "        final_xgb_model = xgb.train(xgb_params, xgb.DMatrix(train_x, train_y), self.ROUND, evals=eval_list, maximize=False, verbose_eval=50, early_stopping_rounds=50)\n",
    "        valid_preds = final_xgb_model.predict(xgb.DMatrix(valid_x), ntree_limit=final_xgb_model.best_ntree_limit).clip(0.0000001, 0.999999)\n",
    "        test_preds = final_xgb_model.predict(xgb.DMatrix(self.test_x), ntree_limit=final_xgb_model.best_ntree_limit).clip(0.0000001, 0.999999)\n",
    "        self.model = final_xgb_model\n",
    "        return valid_preds, test_preds, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SklearnModel(ClfModel):\n",
    "    def __init__(self, clf, params, kfold, clfname='sklearn', SEED=0, predict_method='proba', parallel=False, parallel_kernel=None):\n",
    "        params['random_state'] = SEED\n",
    "        self.parallel = parallel\n",
    "        self.parallel_kernel = parallel_kernel\n",
    "        if not self.parallel or not self.parallel_kernel:\n",
    "            self.clf = clf(**params)\n",
    "            self.use_parallel = False\n",
    "        else:\n",
    "            self.clf = [clf(**params) for i in range(kfold.n_folds)]\n",
    "            self.use_parallel = True\n",
    "        self.new_feature_cols = []\n",
    "        self.kfold = kfold\n",
    "        self.SEED = SEED\n",
    "        self.clfname = clfname\n",
    "        self.predict_method = predict_method\n",
    "        \n",
    "    def train_pred(self, train_x, train_y, test_x, test_split_ratio = 0.3, valid_x = None, valid_y = None):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.n_classes_ = len(set(train_y))\n",
    "        self.new_feature_cols = []\n",
    "        self.valid_x = valid_x\n",
    "        self.valid_y = valid_y\n",
    "        if self.kfold is not None:\n",
    "            return self.__train_use_kfold(self.kfold)\n",
    "        else:\n",
    "            return self.__train_use_splitratio(test_split_ratio)\n",
    "        \n",
    "    def __train_use_kfold(self, kfold):\n",
    "        feature_cols = 1\n",
    "        if self.predict_method == \"proba\" or self.predict_method == \"log_proba\":\n",
    "            feature_cols = self.n_classes_\n",
    "        training_prediction = np.zeros((self.train_x.shape[0], feature_cols))\n",
    "        test_prediction = np.empty((kfold.n_folds, self.test_x.shape[0], feature_cols))\n",
    "        for i, (train_index, test_index) in enumerate(kfold):\n",
    "            print(self.clfname + (\" training round %d\" % i))\n",
    "            train_data_x = self.train_x[train_index]\n",
    "            train_data_y = self.train_y[train_index]\n",
    "            training_test_data_x = self.train_x[test_index]\n",
    "            training_test_data_y = self.train_y[test_index]\n",
    "            if not self.use_parallel:\n",
    "                self.clf.fit(train_data_x, train_data_y)\n",
    "                if self.predict_method == \"proba\":\n",
    "                    training_prediction[test_index] = self.clf.predict_proba(training_test_data_x)\n",
    "                    test_prediction[i, :] = self.clf.predict_proba(self.test_x)\n",
    "                elif self.predict_method == \"log_proba\":\n",
    "                    training_prediction[test_index] = self.clf.predict_log_proba(training_test_data_x)\n",
    "                    test_prediction[i, :] = self.clf.predict_log_proba(self.test_x)\n",
    "                else:\n",
    "                    training_prediction[test_index] = self.clf.predict(training_test_data_x).reshape(-1, 1)\n",
    "                    test_prediction[i, :] = self.clf.predict(self.test_x).reshape(-1, 1)\n",
    "            else:\n",
    "                inner_item = {\"clf\": self.clf[i], \"predict_method\": self.predict_method, \"round_i\": i, \"test_index\": test_index,\n",
    "                              \"train_data_x\": train_data_x, \"train_data_y\": train_data_y, \"test_x\": self.test_x,\n",
    "                              \"training_test_data_x\": training_test_data_x, \"training_test_data_y\": training_test_data_y\n",
    "                             }\n",
    "                if i == 0:\n",
    "                    parallel_data = [inner_item]\n",
    "                else:\n",
    "                    parallel_data.append(inner_item)\n",
    "        classes = []\n",
    "        if self.use_parallel:\n",
    "            self.pool = Pool(cpu_count())\n",
    "            predsResult = self.pool.map(self.parallel_kernel, parallel_data)\n",
    "            for predsItem in predsResult:\n",
    "                training_prediction_item, test_prediction_item, round_i, test_index_item, classes_ = predsItem\n",
    "                training_prediction[test_index_item] = training_prediction_item\n",
    "                test_prediction[round_i, :] = test_prediction_item\n",
    "                classes.append(classes_)\n",
    "            self.pool.close()\n",
    "            self.pool.join()\n",
    "            if self.predict_method == \"proba\" or self.predict_method == \"log_proba\":\n",
    "                classes_max_len = -1\n",
    "                tmp_classes = None\n",
    "                # get real classes_, which has the maximum length\n",
    "                for class_ in classes:\n",
    "                    if len(class_) > classes_max_len:\n",
    "                        classes_max_len = len(class_)\n",
    "                        tmp_classes = class_\n",
    "                classes = tmp_classes\n",
    "            else:\n",
    "                classes = [1]\n",
    "        training_prediction = training_prediction.clip(0.0000001, 0.999999)\n",
    "        test_prediction = test_prediction.clip(0.0000001, 0.999999)\n",
    "        training_prediction_dataframe = None\n",
    "        test_prediction_dataframe = None\n",
    "        for i in range(feature_cols):\n",
    "            new_feature = ClfModel.feature_name_prefix % (self.clfname, ClfModel.feature_index)\n",
    "            ClfModel.feature_index += 1\n",
    "            self.new_feature_cols += [new_feature]\n",
    "            cur_train_df = pd.DataFrame(training_prediction[:, i], columns=[new_feature])\n",
    "            cur_test_df = pd.DataFrame(test_prediction[:, :, i].mean(axis=0).reshape(-1, 1), columns=[new_feature])\n",
    "            if i != 0:\n",
    "                training_prediction_dataframe = pd.concat([training_prediction_dataframe, cur_train_df], axis=1)\n",
    "                test_prediction_dataframe = pd.concat([test_prediction_dataframe, cur_test_df], axis=1)\n",
    "            else:\n",
    "                training_prediction_dataframe = cur_train_df\n",
    "                test_prediction_dataframe = cur_test_df\n",
    "        print(self.new_feature_cols)\n",
    "        del self.train_x\n",
    "        del self.train_y\n",
    "        del self.test_x\n",
    "        del training_prediction\n",
    "        del test_prediction\n",
    "        gc.collect()\n",
    "        return training_prediction_dataframe, test_prediction_dataframe, self.new_feature_cols, list(set(classes))\n",
    "        \n",
    "    def __train_use_splitratio(self, ratio):\n",
    "        print(\"stacking training.\")\n",
    "        if ratio > 0:\n",
    "            train_x, valid_x, train_y, valid_y = model_selection.train_test_split(self.train_x, self.train_y, test_size=ratio, random_state=self.SEED)\n",
    "        else:\n",
    "            train_x = self.train_x\n",
    "            train_y = self.train_y\n",
    "            if self.valid_x is None or self.valid_y is None:\n",
    "                valid_x = self.train_x\n",
    "                valid_y = self.train_y\n",
    "            else:\n",
    "                valid_x = self.valid_x\n",
    "                valid_y = self.valid_y\n",
    "        self.clf.fit(train_x, train_y)\n",
    "        valid_preds = self.clf.predict(valid_x).clip(0.0000001, 0.999999)\n",
    "        test_preds = self.clf.predict(self.test_x).clip(0.0000001, 0.999999)\n",
    "        del self.train_x\n",
    "        del self.train_y\n",
    "        del self.test_x\n",
    "        gc.collect()\n",
    "        return valid_preds, test_preds, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClfFeaturePipline(object):\n",
    "    def __init__(self, train, test, train_data_x, train_data_y, test_data, clf_ins_list):\n",
    "        self.final_train_data = train\n",
    "        self.final_test_data = test\n",
    "        self.train_data_x = train_data_x\n",
    "        self.train_data_y  = train_data_y\n",
    "        self.test_data = test_data\n",
    "        self.clf_ins_list = clf_ins_list\n",
    "        self.feature_cols = []\n",
    "        self.n_classes_feature_cols_map = {}\n",
    "    \n",
    "    def train_pred(self):\n",
    "        self.feature_cols = []\n",
    "        for clf in self.clf_ins_list:\n",
    "            training_predctions, test_predictions, new_feature_cols, classes = clf.train_pred(self.train_data_x, self.train_data_y, self.test_data)\n",
    "            self.final_train_data = pd.concat([self.final_train_data, training_predctions], axis=1)\n",
    "            self.final_test_data = pd.concat([self.final_test_data, test_predictions], axis=1)\n",
    "            self.feature_cols = self.feature_cols + new_feature_cols\n",
    "            for i, class_name in enumerate(classes):\n",
    "                class_name = str(class_name)\n",
    "                if class_name not in self.n_classes_feature_cols_map:\n",
    "                    self.n_classes_feature_cols_map[class_name] = []\n",
    "                self.n_classes_feature_cols_map[class_name].append(new_feature_cols[i])\n",
    "            del training_predctions\n",
    "            del test_predictions\n",
    "        gc.collect()\n",
    "        return self.final_train_data, self.final_test_data, self.feature_cols, self.n_classes_feature_cols_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb features\n",
    "xgb_params = {\n",
    "    'eta': 0.02, #use 0.002\n",
    "    'max_depth': 7,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'seed': i,\n",
    "    'silent': True,       \n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "# random forest features\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': False, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'probability': True,\n",
    "    'C' : 0.025\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NFOLDS = 5\n",
    "SEED = 0\n",
    "ROUND = 200\n",
    "forest_layers = 2 # round need to train\n",
    "cur_index = 6 # change depend on training process\n",
    "train_data = train#train.sample(80000, random_state=SEED).reset_index(drop=True)\n",
    "test_data = test#train.sample(80000, random_state=SEED+5).reset_index(drop=True)#test.sample(80000, random_state=SEED).reset_index(drop=True)\n",
    "scaler = StandardScaler()\n",
    "kf = KFold(train_data.shape[0], n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "ClfModel.feature_index = 42 # feature index start pos\n",
    "xgb_model = XgbModel(xgb_params, kf, ROUND=ROUND)\n",
    "rf_model = SklearnModel(RandomForestClassifier, rf_params, kf, \"rf\", SEED, parallel=True, parallel_kernel=func.sklearn_kernel)\n",
    "et_model = SklearnModel(ExtraTreesClassifier, et_params, kf, \"et\", SEED, parallel=True, parallel_kernel=func.sklearn_kernel)\n",
    "ada_model = SklearnModel(AdaBoostClassifier, ada_params, kf, \"ada\", SEED, parallel=True, parallel_kernel=func.sklearn_kernel)\n",
    "gp_model = SklearnModel(GradientBoostingClassifier, gb_params, kf, \"gp\", SEED, parallel=True, parallel_kernel=func.sklearn_kernel)\n",
    "svc_model = SklearnModel(SVC, svc_params, kf, \"svc\", SEED)\n",
    "\n",
    "# final_train_data = train_data # if training first time\n",
    "# final_test_data = test_data # if training first time\n",
    "train_data_y = train_data[\"is_churn\"].values\n",
    "# new_feature_cols = cols\n",
    "\n",
    "for i in range(forest_layers):\n",
    "    cur_index += i\n",
    "    print(\"----------forest layer %d\" % cur_index)\n",
    "    %time final_train_data_x = scaler.fit_transform(final_train_data[new_feature_cols].values)\n",
    "    %time final_test_data_x = scaler.fit_transform(final_test_data[new_feature_cols].values)\n",
    "    %time final_train_data, final_test_data, added_feature_cols, classes_features_map = ClfFeaturePipline(final_train_data, final_test_data, final_train_data_x, train_data_y, final_test_data_x, [xgb_model, rf_model, et_model, gp_model]).train_pred()\n",
    "    print(\"-----%d--classes_features_map---\" % cur_index, classes_features_map)\n",
    "    final_train_data.to_csv('final_train_data_layer%d.csv' % cur_index, index=False)\n",
    "    final_test_data.to_csv('final_test_data_layer%d.csv' % cur_index, index=False)\n",
    "    json.dump(classes_features_map, open('classes_features_map_layer-%d.txt' % cur_index, 'w'), ensure_ascii=False)\n",
    "    new_feature_cols = new_feature_cols + added_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "final_train_data = pd.read_csv('final_train_data_layer%d.csv' % i)\n",
    "final_test_data = pd.read_csv('final_test_data_layer%d.csv' % i)\n",
    "new_feature_cols = cols\n",
    "for j in range(i + 1):\n",
    "    classes_features_map = json.load(open('classes_features_map_layer-%d.txt' % j))\n",
    "    added_feature_cols = classes_features_map['0'] + classes_features_map['1']\n",
    "    new_feature_cols += added_feature_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(18,18))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(final_train_data[new_feature_cols + [\"is_churn\"]].astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_xgb_model = XgbModel(xgb_params, ROUND=ROUND)\n",
    "validation_preds, final_preds, validation_y = final_xgb_model.train_pred(final_train_data[new_feature_cols], final_train_data['is_churn'], final_test_data[new_feature_cols], -1)\n",
    "# validation_preds, final_preds, validation_y = final_xgb_model.train_pred(final_train_data[new_feature_cols], final_train_data['is_churn'], final_test_data[new_feature_cols], -1, final_test_data[new_feature_cols], final_test_data['is_churn'])\n",
    "test['is_churn'] = final_preds\n",
    "test[['msno','is_churn']].to_csv('submission.csv.gz', index=False, compression='gzip')\n",
    "del final_preds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another preds\n",
    "# final_test_data['is_churn'] = final_test_data[classes_features_map[1]].mean(axis=1)\n",
    "# final_test_data[['msno','is_churn']].to_csv('submission-mean.csv.gz', index=False, compression='gzip')\n",
    "# validation_preds = final_train_data[classes_features_map[1]].mean(axis=1)\n",
    "# validation_y = train_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "xgb.plot_importance(booster=final_xgb_model.model)\n",
    "plt.show()\n",
    "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "plot_precision_recall_vs_threshold(validation_y, validation_preds)\n",
    "plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "plot_roc_curve(validation_y, validation_preds)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "plot_precision_recall_vs_threshold(final_train_data['is_churn'], final_train_data['xgb_feature_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(validation_preds[:10])\n",
    "print(validation_y[:10])\n",
    "print((np.round(validation_preds) == validation_y).astype(np.int16).sum() / len(validation_y))\n",
    "print(log_loss(final_train_data['is_churn'], validation_preds))\n",
    "#print((np.round(final_train_data[[col for col in final_train_data.columns if \"feature\" in col]].mean(axis=1)) == final_train_data['is_churn']).astype(np.int16).sum() / len(final_train_data))\n",
    "#print((np.round(final_test_data[added_feature_cols].mean(axis=1)) == final_test_data['is_churn']).astype(np.int16).sum() / len(final_test_data))\n",
    "#print(log_loss(final_test_data['is_churn'], np.round(final_test_data[added_feature_cols].mean(axis=1))))\n",
    "final_train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data.iloc[np.where(np.round(final_train_data[[col for col in final_train_data.columns if \"feature\" in col]].mean(axis=1)) != final_train_data['is_churn'])].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del validation_y\n",
    "del validation_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del final_train_data\n",
    "del final_test_data\n",
    "del final_xgb_model\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
