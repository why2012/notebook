{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import importlib\n",
    "SEED = 1234\n",
    "np.random.seed(SEED) \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D, AveragePooling2D, Concatenate, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import mylibs.ResNet as ResNet\n",
    "import mylibs.SENet as SENet\n",
    "importlib.reload(ResNet)\n",
    "importlib.reload(SENet)\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import uniform_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session  \n",
    "# config = tf.ConfigProto()  \n",
    "# config.gpu_options.allow_growth = True\n",
    "# set_session(tf.Session(config=config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\kaggle\\iceberg\n"
     ]
    }
   ],
   "source": [
    "%cd E:\\kaggle\\iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "\n",
    "    return np.array(imgs)\n",
    "\n",
    "def get_more_images(imgs):\n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "    vh_flip_imgs = []\n",
    "      \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        vert_flip_imgs.append(cv2.flip(imgs[i], 1))\n",
    "        hori_flip_imgs.append(cv2.flip(imgs[i], 0))\n",
    "        vh_flip_imgs.append(cv2.flip(imgs[i], -1))\n",
    "      \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "    vh = np.array(vh_flip_imgs)\n",
    "       \n",
    "    more_images = np.concatenate((imgs,v,h, vh))\n",
    "    \n",
    "    return more_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(band_1, band_2, is_iceberg, angle = None):\n",
    "    if angle is None:\n",
    "        title_str = 'Iceberg' if is_iceberg == 1 else 'Ship'\n",
    "    else:\n",
    "        title_str = 'Iceberg-' + str(angle) if is_iceberg == 1 else 'Ship-' + str(angle)\n",
    "    fig = plt.figure(0, figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.set_title(title_str + ' - Band 1')\n",
    "    ax.imshow(band_1,cmap='jet')\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.set_title(title_str + ' - Band 2')\n",
    "    ax.imshow(band_2,cmap='jet')\n",
    "    plt.show()\n",
    "\n",
    "# implement functions to convert SAR data from decibel units to linear units and back again\n",
    "def decibel_to_linear(band):\n",
    "     # convert to linear units\n",
    "    return np.power(10,np.array(band)/10)\n",
    "\n",
    "def linear_to_decibel(band):\n",
    "    return 10*np.log10(band)\n",
    "\n",
    "# implement the Lee Filter for a band in an image already reshaped into the proper dimensions\n",
    "def lee_filter(band, window, var_noise = 0.25):\n",
    "    # band: SAR data to be despeckled (already reshaped into image dimensions)\n",
    "    # window: descpeckling filter window (tuple)\n",
    "    # default noise variance = 0.25\n",
    "    # assumes noise mean = 0\n",
    "    \n",
    "    mean_window = uniform_filter(band, window)\n",
    "    mean_sqr_window = uniform_filter(band**2, window)\n",
    "    var_window = mean_sqr_window - mean_window**2\n",
    "\n",
    "    weights = var_window / (var_window + var_noise)\n",
    "    band_filtered = mean_window + weights*(band - mean_window)\n",
    "    return band_filtered\n",
    "\n",
    "def apply_lee_filter(band_1_linear, band_2_linear, window_var_index = 0, noise_var_index = 0):\n",
    "    windows = [2, 4, 8] # can be tuple too if not symetric\n",
    "    noise_var = np.array([1, 2, 4])\n",
    "    noise_var_1 = np.round(np.var(band_1_linear) * noise_var, 10)\n",
    "    noise_var_2 = np.round(np.var(band_2_linear) * noise_var, 10)\n",
    "    band_1_linear_filtered = lee_filter(band_1_linear, windows[window_var_index], noise_var_1[noise_var_index])\n",
    "    band_2_linear_filtered = lee_filter(band_2_linear, windows[window_var_index], noise_var_2[noise_var_index])\n",
    "    return band_1_linear_filtered, band_2_linear_filtered\n",
    "\n",
    "def apply_lee_filter_single(band_linear, window_var_index = 0, noise_var_index = 0):\n",
    "    windows = [2, 4, 8] # can be tuple too if not symetric\n",
    "    noise_var = np.array([1, 2, 4])\n",
    "    noise_var = np.round(np.var(band_linear) * noise_var, 10)\n",
    "    band_linear_filtered = lee_filter(band_linear, windows[window_var_index], noise_var[noise_var_index])\n",
    "    return band_linear_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_custom_augmentation = False\n",
    "if use_custom_augmentation:\n",
    "    df_train = pd.read_json('E:/kaggle/iceberg/train.json/data/processed/train.json')\n",
    "    df_test = pd.read_json('E:/kaggle/iceberg/test.json/data/processed/test.json')\n",
    "    Xtrain = get_scaled_imgs(df_train)\n",
    "    Xtest = get_scaled_imgs(df_test)\n",
    "    Ytrain = np.array(df_train['is_iceberg'])\n",
    "    \n",
    "    df_train[\"inc_angle\"] = df_train[\"inc_angle\"].replace('na',0)\n",
    "    df_test[\"inc_angle\"] = df_test[\"inc_angle\"].replace('na',0)\n",
    "    idx_tr = np.where(df_train[\"inc_angle\"]>0)\n",
    "    Xtrain = Xtrain[idx_tr[0]]\n",
    "    Ytrain = Ytrain[idx_tr[0]]\n",
    "    \n",
    "    Xtrain = get_more_images(Xtrain) \n",
    "    Ytrain = np.concatenate((Ytrain,Ytrain,Ytrain, Ytrain))\n",
    "else:\n",
    "    train = pd.read_json(\"E:/kaggle/iceberg/train.json/data/processed/train.json\")\n",
    "    target_train=train['is_iceberg']\n",
    "    test = pd.read_json(\"E:/kaggle/iceberg/test.json/data/processed/test.json\")\n",
    "    \n",
    "    train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "    test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "    train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "    test['inc_angle']=test['inc_angle'].fillna(method='pad')\n",
    "    X_angle=train['inc_angle']\n",
    "    X_test_angle=test['inc_angle']\n",
    "    \n",
    "    #Generate the training data\n",
    "    X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "    X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "    #apply filter\n",
    "    X_band_1_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_1])\n",
    "    X_band_2_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_2])\n",
    "    X_band_1_filtered = linear_to_decibel(X_band_1_filtered)\n",
    "    X_band_2_filtered = linear_to_decibel(X_band_2_filtered)\n",
    "    X_band_1 = X_band_1_filtered\n",
    "    X_band_2 = X_band_2_filtered\n",
    "\n",
    "    X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "    X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "    X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "    X_train = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "    X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "    X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "    #apply filter\n",
    "    X_band_test_1_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_test_1])\n",
    "    X_band_test_2_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_test_2])\n",
    "    X_band_test_1_filtered = linear_to_decibel(X_band_test_1_filtered)\n",
    "    X_band_test_2_filtered = linear_to_decibel(X_band_test_2_filtered)\n",
    "    X_band_test_1 = X_band_test_1_filtered\n",
    "    X_band_test_2 = X_band_test_2_filtered\n",
    "\n",
    "    X_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\n",
    "    X_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\n",
    "    X_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n",
    "    X_test = np.concatenate([X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)\n",
    "    \n",
    "    X_train = get_more_images(X_train)\n",
    "    target_train = np.concatenate((target_train, target_train, target_train, target_train))\n",
    "    X_angle = np.concatenate((X_angle, X_angle, X_angle, X_angle))\n",
    "    \n",
    "    Xtrain = X_train\n",
    "    Ytrain = target_train\n",
    "    Xtest = X_test\n",
    "    Xangle = X_angle\n",
    "    Xangle_test = X_test_angle\n",
    "    df_train = train\n",
    "    df_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6416, 75, 75, 3) (6416,) (6416,) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape, Ytrain.shape, Xangle.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEtCAYAAAAsgeXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMUPglyljjDHGmCHwy5QxxhhjzBD8PzTZHA1Hg9jYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21115c685c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_img(X_band_1[0], X_band_2[0], target_train[0], X_angle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16, ResNet50, SENet50\n",
    "baseModelName = \"ResNet18\"\n",
    "useAngle = False\n",
    "def getModel(baseModelName):\n",
    "    global useAngle\n",
    "    angle_input = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1)(angle_input)\n",
    "    if baseModelName == \"VGG16\":\n",
    "        baseModel = VGG16(weights='imagenet', include_top=False, input_shape=Xtrain.shape[1:], pooling = \"avg\")\n",
    "        cnnOutput = baseModel.output\n",
    "    elif baseModelName == \"ResNet50\":\n",
    "        baseModel = ResNet.ResNet50(weights='imagenet', include_top=False, input_shape=Xtrain.shape[1:], pooling = \"avg\")\n",
    "        cnnOutput = baseModel.output\n",
    "#         cnnOutput = baseModel.get_layer(\"final\").output\n",
    "#         cnnOutput = AveragePooling2D((3, 3), name='avg_pool')(cnnOutput)\n",
    "#         cnnOutput = GlobalAveragePooling2D(name = \"global_avg_pool\")(cnnOutput)\n",
    "    elif baseModelName == \"SENet50\":\n",
    "        baseModel = SENet.SENet50(weights='imagenet', include_top=False, input_shape=Xtrain.shape[1:], pooling = \"avg\",\n",
    "#                                   kernel_regularizer = \"l2\",\n",
    "#                                   bias_regularizer = \"l2\",\n",
    "#                                   activity_regularizer = None,\n",
    "#                                   regularizer_value = 1e-4\n",
    "                                 )\n",
    "#         cnnOutput = baseModel.output\n",
    "        cnnOutput = baseModel.get_layer(\"final\").output\n",
    "        cnnOutput = AveragePooling2D((3, 3), name='avg_pool')(cnnOutput)\n",
    "        cnnOutput = GlobalAveragePooling2D(name = \"global_avg_pool\")(cnnOutput)\n",
    "    elif baseModelName == \"ResNet18\":\n",
    "        baseModel = ResNet.ResNet18(weights='imagenet', include_top=False, input_shape=Xtrain.shape[1:])\n",
    "        cnnOutput = baseModel.get_layer(\"final\").output\n",
    "\n",
    "    if baseModelName == \"VGG16\":\n",
    "        fcOutput = Dropout(0.6)(cnnOutput)\n",
    "        predictions = Dense(1, activation=\"sigmoid\")(fcOutput)\n",
    "        model = Model(inputs=baseModel.input, outputs=predictions)\n",
    "    elif baseModelName == \"ResNet50\":\n",
    "        useAngle = True\n",
    "        predictions = Dense(1, activation=\"sigmoid\")(Concatenate()([Dropout(0.6)(cnnOutput), angle_layer]))\n",
    "        model = Model(inputs=[baseModel.input, angle_input], outputs=predictions)\n",
    "    elif baseModelName == \"SENet50\":\n",
    "        predictions = Dense(1, activation=\"sigmoid\")(cnnOutput)\n",
    "        model = Model(inputs=baseModel.input, outputs=predictions)\n",
    "    elif baseModelName == \"ResNet18\":\n",
    "        useAngle = True\n",
    "        cnnOutput = Dropout(0.6)(Flatten()(cnnOutput))\n",
    "        predictions = Dense(1, activation=\"sigmoid\")(Concatenate()([cnnOutput, angle_layer]))\n",
    "        model = Model(inputs=[baseModel.input, angle_input], outputs=predictions)\n",
    "    \n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 38, 38, 16)    2368        input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_217 (Activation)      (None, 38, 38, 16)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D)  (None, 18, 18, 16)    0           activation_217[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 18, 18, 16)    2320        max_pooling2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 18, 18, 16)    64          res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_218 (Activation)      (None, 18, 18, 16)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 18, 18, 16)    2320        activation_218[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 18, 18, 16)    64          res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_219 (Activation)      (None, 18, 18, 16)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 18, 18, 16)    2320        max_pooling2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "add_73 (Add)                     (None, 18, 18, 16)    0           activation_219[0][0]             \n",
      "                                                                   res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_220 (Activation)      (None, 18, 18, 16)    0           add_73[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 18, 18, 16)    2320        activation_220[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 18, 18, 16)    64          res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_221 (Activation)      (None, 18, 18, 16)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 18, 18, 16)    2320        activation_221[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 18, 18, 16)    64          res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_222 (Activation)      (None, 18, 18, 16)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_74 (Add)                     (None, 18, 18, 16)    0           activation_222[0][0]             \n",
      "                                                                   activation_220[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_223 (Activation)      (None, 18, 18, 16)    0           add_74[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 18, 18, 16)    0           activation_223[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 8, 8, 32)      4640        dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 8, 8, 32)      128         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_224 (Activation)      (None, 8, 8, 32)      0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 8, 8, 32)      9248        activation_224[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 8, 8, 32)      128         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_225 (Activation)      (None, 8, 8, 32)      0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 8, 8, 32)      4640        dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_75 (Add)                     (None, 8, 8, 32)      0           activation_225[0][0]             \n",
      "                                                                   res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_226 (Activation)      (None, 8, 8, 32)      0           add_75[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 8, 8, 32)      9248        activation_226[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 8, 8, 32)      128         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_227 (Activation)      (None, 8, 8, 32)      0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 8, 8, 32)      9248        activation_227[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 8, 8, 32)      128         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_228 (Activation)      (None, 8, 8, 32)      0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_76 (Add)                     (None, 8, 8, 32)      0           activation_228[0][0]             \n",
      "                                                                   activation_226[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_229 (Activation)      (None, 8, 8, 32)      0           add_76[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 8, 8, 32)      0           activation_229[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 3, 3, 64)      18496       dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 3, 3, 64)      256         res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_230 (Activation)      (None, 3, 3, 64)      0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 3, 3, 64)      36928       activation_230[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 3, 3, 64)      256         res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_231 (Activation)      (None, 3, 3, 64)      0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 3, 3, 64)      18496       dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_77 (Add)                     (None, 3, 3, 64)      0           activation_231[0][0]             \n",
      "                                                                   res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_232 (Activation)      (None, 3, 3, 64)      0           add_77[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 3, 3, 64)      36928       activation_232[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 3, 3, 64)      256         res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_233 (Activation)      (None, 3, 3, 64)      0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 3, 3, 64)      36928       activation_233[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 3, 3, 64)      256         res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_234 (Activation)      (None, 3, 3, 64)      0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_78 (Add)                     (None, 3, 3, 64)      0           activation_234[0][0]             \n",
      "                                                                   activation_232[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_235 (Activation)      (None, 3, 3, 64)      0           add_78[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 3, 3, 64)      0           activation_235[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 1, 1, 128)     73856       dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 1, 1, 128)     512         res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_236 (Activation)      (None, 1, 1, 128)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 1, 1, 128)     147584      activation_236[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 1, 1, 128)     512         res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_237 (Activation)      (None, 1, 1, 128)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 1, 1, 128)     73856       dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_79 (Add)                     (None, 1, 1, 128)     0           activation_237[0][0]             \n",
      "                                                                   res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_238 (Activation)      (None, 1, 1, 128)     0           add_79[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 1, 1, 128)     147584      activation_238[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 1, 1, 128)     512         res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_239 (Activation)      (None, 1, 1, 128)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 1, 1, 128)     147584      activation_239[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 1, 1, 128)     512         res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_240 (Activation)      (None, 1, 1, 128)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_80 (Add)                     (None, 1, 1, 128)     0           activation_240[0][0]             \n",
      "                                                                   activation_238[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_241 (Activation)      (None, 1, 1, 128)     0           add_80[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "final (Dropout)                  (None, 1, 1, 128)     0           activation_241[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)             (None, 128)           0           final[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "angle (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 128)           0           flatten_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_20 (Dense)                 (None, 1)             2           angle[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)     (None, 129)           0           dropout_17[0][0]                 \n",
      "                                                                   dense_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_21 (Dense)                 (None, 1)             130         concatenate_10[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 793,204\n",
      "Trainable params: 791,284\n",
      "Non-trainable params: 1,920\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel(baseModelName)\n",
    "model.summary()\n",
    "plot_model(model, to_file=baseModelName.lower() + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if sys.version_info[1] == 5:\n",
    "#     batch_size = 32\n",
    "# else:\n",
    "#     batch_size = 64\n",
    "batch_size = 64\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=8, verbose=1, epsilon=1e-4, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Train on 4277 samples, validate on 2139 samples\n",
      "Epoch 1/100\n",
      "4277/4277 [==============================] - 73s - loss: 1.9478 - acc: 0.5155 - val_loss: 1.3617 - val_acc: 0.5306\n",
      "Epoch 2/100\n",
      "4277/4277 [==============================] - 15s - loss: 1.2048 - acc: 0.5417 - val_loss: 1.0651 - val_acc: 0.530660 - acc\n",
      "Epoch 3/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.9607 - acc: 0.5558 - val_loss: 0.9110 - val_acc: 0.5306\n",
      "Epoch 4/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.8025 - acc: 0.5756 - val_loss: 0.7899 - val_acc: 0.5302\n",
      "Epoch 5/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.7149 - acc: 0.6025 - val_loss: 0.6716 - val_acc: 0.5259\n",
      "Epoch 6/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.6923 - acc: 0.6081 - val_loss: 0.6095 - val_acc: 0.5484\n",
      "Epoch 7/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.6790 - acc: 0.6049 - val_loss: 0.5885 - val_acc: 0.6045\n",
      "Epoch 8/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.6721 - acc: 0.5885 - val_loss: 0.5798 - val_acc: 0.6592\n",
      "Epoch 9/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.6350 - acc: 0.6182 - val_loss: 0.5627 - val_acc: 0.6844\n",
      "Epoch 10/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.6250 - acc: 0.6336 - val_loss: 0.5666 - val_acc: 0.6840\n",
      "Epoch 11/100\n",
      "4277/4277 [==============================] - 18s - loss: 0.6171 - acc: 0.6364 - val_loss: 0.5554 - val_acc: 0.6933\n",
      "Epoch 12/100\n",
      "4277/4277 [==============================] - 18s - loss: 0.6056 - acc: 0.6434 - val_loss: 0.5477 - val_acc: 0.6928\n",
      "Epoch 13/100\n",
      "4277/4277 [==============================] - 19s - loss: 0.5926 - acc: 0.6507 - val_loss: 0.5365 - val_acc: 0.7055\n",
      "Epoch 14/100\n",
      "4277/4277 [==============================] - 19s - loss: 0.5988 - acc: 0.6460 - val_loss: 0.5474 - val_acc: 0.6999\n",
      "Epoch 15/100\n",
      "4277/4277 [==============================] - 21s - loss: 0.5822 - acc: 0.6638 - val_loss: 0.5317 - val_acc: 0.7115\n",
      "Epoch 16/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.5707 - acc: 0.6720 - val_loss: 0.5101 - val_acc: 0.7270\n",
      "Epoch 17/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.5653 - acc: 0.6787 - val_loss: 0.4955 - val_acc: 0.7405\n",
      "Epoch 18/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.5485 - acc: 0.6890 - val_loss: 0.4764 - val_acc: 0.7564.6\n",
      "Epoch 19/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.5170 - acc: 0.7257 - val_loss: 0.4645 - val_acc: 0.7532\n",
      "Epoch 20/100\n",
      "4277/4277 [==============================] - 14s - loss: 0.5047 - acc: 0.7393 - val_loss: 0.4860 - val_acc: 0.7396\n",
      "Epoch 21/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.4663 - acc: 0.7622 - val_loss: 0.4508 - val_acc: 0.7705\n",
      "Epoch 22/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.4365 - acc: 0.7851 - val_loss: 0.4074 - val_acc: 0.8022\n",
      "Epoch 23/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.4315 - acc: 0.7884 - val_loss: 0.4259 - val_acc: 0.7793oss: 0.4372 - acc: 0 - ETA: 8s - loss: 0.4285 - - ETA: 5s - loss: 0.4361 - acc: - ETA: 3s - loss: 0\n",
      "Epoch 24/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.4164 - acc: 0.8048 - val_loss: 0.3713 - val_acc: 0.8294\n",
      "Epoch 25/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.3962 - acc: 0.8134 - val_loss: 0.3572 - val_acc: 0.8396\n",
      "Epoch 26/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3750 - acc: 0.8221 - val_loss: 0.3779 - val_acc: 0.8373\n",
      "Epoch 27/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.3664 - acc: 0.8324 - val_loss: 0.3479 - val_acc: 0.8434\n",
      "Epoch 28/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3661 - acc: 0.8326 - val_loss: 0.3668 - val_acc: 0.8340\n",
      "Epoch 29/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3524 - acc: 0.8405 - val_loss: 0.4383 - val_acc: 0.8125\n",
      "Epoch 30/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.3353 - acc: 0.8462 - val_loss: 0.3289 - val_acc: 0.8424\n",
      "Epoch 31/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.3254 - acc: 0.8506 - val_loss: 0.3072 - val_acc: 0.8733\n",
      "Epoch 32/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3203 - acc: 0.8560 - val_loss: 0.3332 - val_acc: 0.8453\n",
      "Epoch 33/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3192 - acc: 0.8574 - val_loss: 0.3446 - val_acc: 0.8252\n",
      "Epoch 34/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3049 - acc: 0.8604 - val_loss: 0.3410 - val_acc: 0.8686\n",
      "Epoch 35/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.3122 - acc: 0.8625 - val_loss: 0.3954 - val_acc: 0.8490\n",
      "Epoch 36/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2858 - acc: 0.8681 - val_loss: 0.3222 - val_acc: 0.8668\n",
      "Epoch 37/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.2898 - acc: 0.8677 - val_loss: 0.4054 - val_acc: 0.7831\n",
      "Epoch 38/100\n",
      "4277/4277 [==============================] - 20s - loss: 0.2813 - acc: 0.8794 - val_loss: 0.4006 - val_acc: 0.8546\n",
      "Epoch 39/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2853 - acc: 0.8756 - val_loss: 0.4599 - val_acc: 0.8373\n",
      "Epoch 40/100\n",
      "4224/4277 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.8809\n",
      "Epoch 00039: reducing learning rate to 3.9999998989515007e-05.\n",
      "4277/4277 [==============================] - 19s - loss: 0.2782 - acc: 0.8815 - val_loss: 0.3214 - val_acc: 0.8742\n",
      "Epoch 41/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.2622 - acc: 0.8864 - val_loss: 0.2869 - val_acc: 0.8766\n",
      "Epoch 42/100\n",
      "4277/4277 [==============================] - 18s - loss: 0.2544 - acc: 0.8880 - val_loss: 0.3284 - val_acc: 0.8686\n",
      "Epoch 43/100\n",
      "4277/4277 [==============================] - 21s - loss: 0.2539 - acc: 0.8922 - val_loss: 0.3046 - val_acc: 0.8728\n",
      "Epoch 44/100\n",
      "4277/4277 [==============================] - 19s - loss: 0.2495 - acc: 0.8896 - val_loss: 0.3100 - val_acc: 0.8728\n",
      "Epoch 45/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2495 - acc: 0.8908 - val_loss: 0.3748 - val_acc: 0.8607\n",
      "Epoch 46/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2478 - acc: 0.8929 - val_loss: 0.3347 - val_acc: 0.8705\n",
      "Epoch 47/100\n",
      "4277/4277 [==============================] - 19s - loss: 0.2392 - acc: 0.9013 - val_loss: 0.2995 - val_acc: 0.8714\n",
      "Epoch 48/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.2406 - acc: 0.8927 - val_loss: 0.3162 - val_acc: 0.8457\n",
      "Epoch 49/100\n",
      "4277/4277 [==============================] - 18s - loss: 0.2360 - acc: 0.8976 - val_loss: 0.2803 - val_acc: 0.8836\n",
      "Epoch 50/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.2441 - acc: 0.8995 - val_loss: 0.3164 - val_acc: 0.8756\n",
      "Epoch 51/100\n",
      "4277/4277 [==============================] - 19s - loss: 0.2372 - acc: 0.8974 - val_loss: 0.2730 - val_acc: 0.8827\n",
      "Epoch 52/100\n",
      "4277/4277 [==============================] - 17s - loss: 0.2325 - acc: 0.9062 - val_loss: 0.3253 - val_acc: 0.8789\n",
      "Epoch 53/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2269 - acc: 0.9039 - val_loss: 0.3021 - val_acc: 0.8789\n",
      "Epoch 54/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2284 - acc: 0.8995 - val_loss: 0.3169 - val_acc: 0.8789\n",
      "Epoch 55/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2276 - acc: 0.9060 - val_loss: 0.2739 - val_acc: 0.8784\n",
      "Epoch 56/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2296 - acc: 0.9046 - val_loss: 0.3424 - val_acc: 0.8682\n",
      "Epoch 57/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2311 - acc: 0.9126 - val_loss: 0.2878 - val_acc: 0.8836\n",
      "Epoch 58/100\n",
      "4277/4277 [==============================] - 18s - loss: 0.2285 - acc: 0.9079 - val_loss: 0.2665 - val_acc: 0.8803\n",
      "Epoch 59/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2296 - acc: 0.9039 - val_loss: 0.2758 - val_acc: 0.8827\n",
      "Epoch 60/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2169 - acc: 0.9112 - val_loss: 0.2771 - val_acc: 0.8859\n",
      "Epoch 61/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2065 - acc: 0.9130 - val_loss: 0.3019 - val_acc: 0.8873\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4277/4277 [==============================] - 15s - loss: 0.2244 - acc: 0.9041 - val_loss: 0.3426 - val_acc: 0.8728\n",
      "Epoch 63/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2115 - acc: 0.9114 - val_loss: 0.3796 - val_acc: 0.8719\n",
      "Epoch 64/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2118 - acc: 0.9135 - val_loss: 0.3064 - val_acc: 0.8887\n",
      "Epoch 65/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2059 - acc: 0.9156 - val_loss: 0.3140 - val_acc: 0.8799\n",
      "Epoch 66/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2155 - acc: 0.9102 - val_loss: 0.2883 - val_acc: 0.8822\n",
      "Epoch 67/100\n",
      "4224/4277 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9122\n",
      "Epoch 00066: reducing learning rate to 1.5999999595806004e-05.\n",
      "4277/4277 [==============================] - 15s - loss: 0.2079 - acc: 0.9119 - val_loss: 0.2738 - val_acc: 0.8827\n",
      "Epoch 68/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2152 - acc: 0.9133 - val_loss: 0.2793 - val_acc: 0.8873\n",
      "Epoch 69/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.1982 - acc: 0.9165 - val_loss: 0.2871 - val_acc: 0.8873\n",
      "Epoch 70/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2016 - acc: 0.9210 - val_loss: 0.2721 - val_acc: 0.8883\n",
      "Epoch 71/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.2000 - acc: 0.9177 - val_loss: 0.2893 - val_acc: 0.8878\n",
      "Epoch 72/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.1910 - acc: 0.9205 - val_loss: 0.3049 - val_acc: 0.8855\n",
      "Epoch 73/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.1935 - acc: 0.9224 - val_loss: 0.2828 - val_acc: 0.8864\n",
      "Epoch 74/100\n",
      "4277/4277 [==============================] - 16s - loss: 0.2008 - acc: 0.9210 - val_loss: 0.3091 - val_acc: 0.8855\n",
      "Epoch 75/100\n",
      "4224/4277 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9167\n",
      "Epoch 00074: reducing learning rate to 6.399999983841554e-06.\n",
      "4277/4277 [==============================] - 15s - loss: 0.1978 - acc: 0.9172 - val_loss: 0.3068 - val_acc: 0.8869\n",
      "Epoch 76/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.1992 - acc: 0.9200 - val_loss: 0.2829 - val_acc: 0.8892\n",
      "Epoch 77/100\n",
      "4277/4277 [==============================] - 14s - loss: 0.1956 - acc: 0.9226 - val_loss: 0.2889 - val_acc: 0.8925\n",
      "Epoch 78/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.1981 - acc: 0.9163 - val_loss: 0.2973 - val_acc: 0.8887\n",
      "Epoch 79/100\n",
      "4277/4277 [==============================] - 15s - loss: 0.1901 - acc: 0.9231 - val_loss: 0.2887 - val_acc: 0.8883\n",
      " 256/6416 [>.............................] - ETA: 12s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c06d709284a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                                steps=steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1337\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1339\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1340\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K=3\n",
    "epochs = 100\n",
    "Kfolds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED).split(Xtrain, Ytrain))\n",
    "y_test_pred_log = 0\n",
    "for j, (train_idx, test_idx) in enumerate(Kfolds):\n",
    "    print('\\n===================FOLD=',j)\n",
    "    Xtrain_cv = Xtrain[train_idx]\n",
    "    Ytrain_cv = Ytrain[train_idx]\n",
    "    Xangle_cv = Xangle[train_idx]\n",
    "    Xtrain_val = Xtrain[test_idx]\n",
    "    Ytrain_val = Ytrain[test_idx]\n",
    "    Xangle_val = Xangle[test_idx]\n",
    "    \n",
    "    model_file = 'model_%s_%s.hdf5' % (baseModelName.lower(), j)\n",
    "    \n",
    "    mcp_save = ModelCheckpoint(model_file, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    model = getModel(baseModelName)\n",
    "    \n",
    "    if useAngle:\n",
    "        Xtrain_cv = [Xtrain_cv, Xangle_cv]\n",
    "        Xtrain_val = [Xtrain_val, Xangle_val]\n",
    "        Xtrain_input = [Xtrain, Xangle]\n",
    "        Xtest_input = [Xtest, Xangle_test]\n",
    "    else:\n",
    "        Xtrain_input = Xtrain\n",
    "        Xtest_input = Xtest\n",
    "        \n",
    "    model.fit(Xtrain_cv, Ytrain_cv, batch_size=batch_size, epochs=epochs, verbose=1, shuffle=True, callbacks=[\n",
    "        earlyStopping, \n",
    "        mcp_save, \n",
    "        reduce_lr_loss, \n",
    "#       tensorboard  \n",
    "    ], validation_data=(Xtrain_val, Ytrain_val))\n",
    "    \n",
    "    model.load_weights(filepath = model_file)    \n",
    "    \n",
    "    score = model.evaluate(Xtrain_input, Ytrain, verbose=1)\n",
    "    print('Train score:', score[0])\n",
    "    print('Train accuracy:', score[1])\n",
    "    y_test_pred_log += model.predict(Xtest_input).reshape(Xtest.shape[0])\n",
    "    \n",
    "y_test_pred_log /= K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': df_test[\"id\"], 'is_iceberg': y_test_pred_log})\n",
    "print(submission.head(10))\n",
    "print(submission.count(), Xtest.shape[0])\n",
    "\n",
    "submission.to_csv('submission-cnn-custom-%s.csv' % baseModelName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
