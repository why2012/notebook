{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\kaggle\\iceberg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import importlib\n",
    "SEED = 1234\n",
    "np.random.seed(SEED) \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D, AveragePooling2D, Concatenate, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Add, GRUCell, GRU, Bidirectional, StackedRNNCells\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras import backend as KB\n",
    "from keras.engine import Layer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import tensor_array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True\n",
    "keras.backend.tensorflow_backend.set_session(tf.Session(config=config)) \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%cd E:\\kaggle\\iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_img(band_1, band_2, is_iceberg, angle = None):\n",
    "    if angle is None:\n",
    "        title_str = 'Iceberg' if is_iceberg == 1 else 'Ship'\n",
    "    else:\n",
    "        title_str = 'Iceberg-' + str(angle) if is_iceberg == 1 else 'Ship-' + str(angle)\n",
    "    fig = plt.figure(0, figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.set_title(title_str + ' - Band 1')\n",
    "    ax.imshow(band_1,cmap='jet')\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.set_title(title_str + ' - Band 2')\n",
    "    ax.imshow(band_2,cmap='jet')\n",
    "    plt.show()\n",
    "\n",
    "# implement functions to convert SAR data from decibel units to linear units and back again\n",
    "def decibel_to_linear(band):\n",
    "     # convert to linear units\n",
    "    return np.power(10,np.array(band)/10)\n",
    "\n",
    "def linear_to_decibel(band):\n",
    "    return 10*np.log10(band)\n",
    "\n",
    "# implement the Lee Filter for a band in an image already reshaped into the proper dimensions\n",
    "def lee_filter(band, window, var_noise = 0.25):\n",
    "    # band: SAR data to be despeckled (already reshaped into image dimensions)\n",
    "    # window: descpeckling filter window (tuple)\n",
    "    # default noise variance = 0.25\n",
    "    # assumes noise mean = 0\n",
    "    \n",
    "    mean_window = uniform_filter(band, window)\n",
    "    mean_sqr_window = uniform_filter(band**2, window)\n",
    "    var_window = mean_sqr_window - mean_window**2\n",
    "\n",
    "    weights = var_window / (var_window + var_noise)\n",
    "    band_filtered = mean_window + weights*(band - mean_window)\n",
    "    return band_filtered\n",
    "\n",
    "def apply_lee_filter(band_1_linear, band_2_linear, window_var_index = 0, noise_var_index = 0):\n",
    "    windows = [2, 4, 8] # can be tuple too if not symetric\n",
    "    noise_var = np.array([1, 2, 4])\n",
    "    noise_var_1 = np.round(np.var(band_1_linear) * noise_var, 10)\n",
    "    noise_var_2 = np.round(np.var(band_2_linear) * noise_var, 10)\n",
    "    band_1_linear_filtered = lee_filter(band_1_linear, windows[window_var_index], noise_var_1[noise_var_index])\n",
    "    band_2_linear_filtered = lee_filter(band_2_linear, windows[window_var_index], noise_var_2[noise_var_index])\n",
    "    return band_1_linear_filtered, band_2_linear_filtered\n",
    "\n",
    "def apply_lee_filter_single(band_linear, window_var_index = 0, noise_var_index = 0):\n",
    "    windows = [2, 4, 8] # can be tuple too if not symetric\n",
    "    noise_var = np.array([1, 2, 4])\n",
    "    noise_var = np.round(np.var(band_linear) * noise_var, 10)\n",
    "    band_linear_filtered = lee_filter(band_linear, windows[window_var_index], noise_var[noise_var_index])\n",
    "    return band_linear_filtered\n",
    "\n",
    "def np_get_scaled_band(band_list):\n",
    "    imgs = []\n",
    "    for band in band_list:        \n",
    "        imgs.append((band - band.mean()) / band.std())\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"E:/kaggle/iceberg/train.json/data/processed/train.json\")\n",
    "Y_train = np.array(train['is_iceberg'])\n",
    "test = pd.read_json(\"E:/kaggle/iceberg/test.json/data/processed/test.json\")\n",
    "\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "test['inc_angle']=test['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "X_test_angle=test['inc_angle']\n",
    "\n",
    "def iso(arr):\n",
    "    arr = np.reshape(arr, (75,75))\n",
    "    p = arr > (np.mean(arr) + 2 * np.std(arr))\n",
    "    return p * arr\n",
    "\n",
    "def size(arr):     \n",
    "    return float(np.sum(arr < -5)) / (75 * 75)\n",
    "\n",
    "train['iso_1'] = train.band_1.apply(iso)\n",
    "train['iso_2'] = train.band_2.apply(iso)\n",
    "train['size_1'] = train.iso_1.apply(size)\n",
    "train['size_2'] = train.iso_2.apply(size)\n",
    "X_size_1 = np.array(train['size_1'])\n",
    "X_size_2 = np.array(train['size_2'])\n",
    "\n",
    "test['iso_1'] = test.band_1.apply(iso)\n",
    "test['iso_2'] = test.band_2.apply(iso)\n",
    "test['size_1'] = test.iso_1.apply(size)\n",
    "test['size_2'] = test.iso_2.apply(size)\n",
    "test_size_1 = np.array(test['size_1'])\n",
    "test_size_2 = np.array(test['size_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "#apply filter\n",
    "X_band_1_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_1])\n",
    "X_band_2_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_2])\n",
    "X_band_1_filtered = linear_to_decibel(X_band_1_filtered)\n",
    "X_band_2_filtered = linear_to_decibel(X_band_2_filtered)\n",
    "X_band_1 = X_band_1_filtered\n",
    "X_band_2 = X_band_2_filtered\n",
    "X_band_mean = (X_band_1 + X_band_2) / 2\n",
    "# construct bands\n",
    "X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "# subtract mean\n",
    "X_band_3 = np_get_scaled_band(X_band_3)\n",
    "X_band_4 = np_get_scaled_band(X_band_4)\n",
    "X_band_5 = np_get_scaled_band(X_band_5)\n",
    "\n",
    "X_train = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "# X_train = np.concatenate([X_band_1[:, :, :, np.newaxis],X_band_2[:, :, :, np.newaxis],X_band_mean[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "#apply filter\n",
    "X_band_test_1_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_test_1])\n",
    "X_band_test_2_filtered = np.array([apply_lee_filter_single(decibel_to_linear(band)) for band in X_band_test_2])\n",
    "X_band_test_1_filtered = linear_to_decibel(X_band_test_1_filtered)\n",
    "X_band_test_2_filtered = linear_to_decibel(X_band_test_2_filtered)\n",
    "X_band_test_1 = X_band_test_1_filtered\n",
    "X_band_test_2 = X_band_test_2_filtered\n",
    "X_band_test_mean = (X_band_test_1 + X_band_test_2) / 2\n",
    "# construct bands\n",
    "X_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\n",
    "X_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\n",
    "X_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n",
    "# subtract mean\n",
    "X_band_test_3 = np_get_scaled_band(X_band_test_3)\n",
    "X_band_test_4 = np_get_scaled_band(X_band_test_4)\n",
    "X_band_test_5 = np_get_scaled_band(X_band_test_5)\n",
    "\n",
    "X_test = np.concatenate([X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)\n",
    "# X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis], X_band_test_2[:, :, :, np.newaxis],X_band_test_mean[:, :, :, np.newaxis]],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resize_shape = tuple(np.array(X_train.shape[1:3]) * 2)\n",
    "# X_train = np.array([cv2.resize(img, resize_shape) for img in X_train])\n",
    "# X_test = np.array([cv2.resize(img, resize_shape) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 75, 75, 3) (1604,) (1604,) (1604,) (8424, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_angle.shape, X_size_1.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    img_input = Input(shape=X_train.shape[1:], name=\"images\")\n",
    "    angle_input = Input(shape=[1], name=\"angle\")\n",
    "    \n",
    "    # ==================== flow1 ====================\n",
    "    flow1_x = img_input\n",
    "    # -------------------- block1 -------------------\n",
    "    flow1_shortcut1 = flow1_x\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block1_conv1')(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block1_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='flow1_block1_pool')(flow1_x)\n",
    "    # -------------------- shortcut1 -------------------\n",
    "    flow1_shortcut1 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', name='flow1_shortcut1')(flow1_shortcut1)\n",
    "    flow1_x = Add(name='flow1_shortcut1_add')([flow1_shortcut1, flow1_x])\n",
    "    flow1_x = Dropout(0.2)(flow1_x)\n",
    "    # -------------------- block2 -------------------\n",
    "    flow1_shortcut2 = flow1_x\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block2_conv1')(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block2_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='flow1_block2_pool')(flow1_x)\n",
    "    # -------------------- shortcut2 -------------------\n",
    "    flow1_shortcut2 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', name='flow1_shortcut2')(flow1_shortcut2)\n",
    "    flow1_x = Add(name='flow1_shortcut2_add')([flow1_shortcut2, flow1_x])\n",
    "    flow1_x = Dropout(0.2)(flow1_x)\n",
    "    # -------------------- block3 -------------------\n",
    "    flow1_shortcut3 = flow1_x\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block3_conv1')(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block3_conv2')(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='flow1_block3_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='flow1_block3_pool')(flow1_x)\n",
    "    # -------------------- shortcut3 -------------------\n",
    "    flow1_shortcut3 = Conv2D(256, (3, 3), strides=(2, 2), activation='relu', padding='same', name='flow1_shortcut3')(flow1_shortcut3)\n",
    "    flow1_x = Add(name='flow1_shortcut3_add')([flow1_shortcut3, flow1_x])\n",
    "    flow1_x = Dropout(0.2)(flow1_x)\n",
    "    # -------------------- block4 -------------------\n",
    "    flow1_shortcut4 = flow1_x\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='flow1_block4_conv1')(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='flow1_block4_conv2')(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='flow1_block4_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='flow1_block4_pool')(flow1_x)\n",
    "    # -------------------- shortcut4 -------------------\n",
    "    flow1_shortcut4 = Conv2D(512, (3, 3), strides=(2, 2), activation='relu', name='flow1_shortcut4')(flow1_shortcut4)\n",
    "    flow1_x = Add(name='flow1_shortcut4_add')([flow1_shortcut4, flow1_x])\n",
    "    flow1_x = Dropout(0.2)(flow1_x)\n",
    "    # -------------------- block5 -------------------\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='flow1_block5_conv1')(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='flow1_block5_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='flow1_block5_pool')(flow1_x)\n",
    "    # -------------------- block6 -------------------\n",
    "    flow1_x = GlobalAveragePooling2D(name='flow1_block6_global_avg')(flow1_x)\n",
    "    flow1_x = Dropout(0.1)(flow1_x)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid', name='predictions')(flow1_x)\n",
    "    model = Model(inputs=img_input, outputs=predictions)\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    Y_train_bak = Y_train\n",
    "    Y_train = OneHotEncoder().fit_transform(Y_train.reshape((-1, 1))).toarray()\n",
    "\n",
    "def getVgg19PlusModel():\n",
    "    img_input = Input(shape=X_train.shape[1:], name=\"images\")\n",
    "    angle_input = Input(shape=[1], name=\"angle\")\n",
    "    size_1 = Input(shape=[1], name=\"size_1\")\n",
    "    size_2 = Input(shape=[1], name=\"size_2\")\n",
    "    \n",
    "    # ==================== flow1 ====================\n",
    "    flow1_x = img_input\n",
    "    # -------------------- block1 -------------------\n",
    "    flow1_x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(flow1_x)\n",
    "    # -------------------- block2 -------------------\n",
    "    flow1_x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(flow1_x)\n",
    "    # -------------------- block3 -------------------\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(flow1_x)\n",
    "    # -------------------- block4 -------------------\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(flow1_x)\n",
    "    # -------------------- block5 -------------------\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(flow1_x)\n",
    "    # -------------------- block6 -------------------\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block6_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block6_conv2')(flow1_x)\n",
    "\n",
    "    \n",
    "    flow1_x = GlobalAveragePooling2D()(flow1_x)\n",
    "    flow1_x = Concatenate()([flow1_x, size_1])\n",
    "    predictions = Dense(2, activation='softmax', name='predictions')(flow1_x)\n",
    "    model = Model(inputs=[img_input, size_1], outputs=predictions)\n",
    "    weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', None, cache_subdir='models')\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    lg = binary_crossentropy\n",
    "    lg.__name__ = \"lg\"\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', lg])\n",
    "    \n",
    "    return model\n",
    "getModel = getVgg19PlusModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionRNNCell_Type1(GRUCell):\n",
    "    def __init__(self, use_initial_states = False, *args, **kwargs):\n",
    "        self.init_args = args\n",
    "        self.init_kwargs = kwargs\n",
    "        self.use_initial_states = use_initial_states\n",
    "        if \"units\" in self.init_kwargs:\n",
    "            del self.init_kwargs[\"units\"]\n",
    "        \n",
    "    def init_context(self, ctx_block):\n",
    "        H, W, C = [int(i) for i in ctx_block.shape[1:]]\n",
    "        units = H * W\n",
    "        ctx_map = tf.reshape(tf.transpose(ctx_block, (0, 3, 1, 2)), (-1, C, units)) # (-1, C, units)\n",
    "        self.ctx_map = ctx_map\n",
    "        self.attention_units = C\n",
    "        super(AttentionRNNCell_Type1, self).__init__(units, *self.init_args, **self.init_kwargs)\n",
    "    \n",
    "    def build(self, input_shape = None):\n",
    "        self.ctx_weight = self.add_weight(shape=(1, 1, self.units),\n",
    "                                      name='ctx_weight',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.ctx_bias = self.add_weight(shape=(1, 1, 1),\n",
    "                                      name='ctx_bias',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.state_weight = self.add_weight(shape=(1, self.units),\n",
    "                                      name='state_weight',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.state_bias = self.add_weight(shape=(1, 1),\n",
    "                                      name='state_bias',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.transform_weight = self.add_weight(shape=(1, 1, self.units),\n",
    "                                      name='transform_weight',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.transform_bias = self.add_weight(shape=(1, 1, 1),\n",
    "                                      name='transform_bias',\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        self.initial_ctx_weight_ones = tf.ones((1, 1, self.units))\n",
    "        self.initial_ctx_weight_zeros = tf.zeros((1, 1, self.units))\n",
    "        super(AttentionRNNCell_Type1, self).build((None, self.units))\n",
    "    \n",
    "    def call(self, inputs, states, time_step, training=None):\n",
    "        h_tm1 = states[0]\n",
    "        if not self.use_initial_states:\n",
    "            ctx_weight = tf.where(tf.equal(time_step, 0), self.initial_ctx_weight_ones, self.ctx_weight)\n",
    "        else:\n",
    "            ctx_weight = tf.where(tf.equal(time_step, 0), self.initial_ctx_weight_zeros, self.ctx_weight)\n",
    "        ctx_attention_term = self.ctx_map * ctx_weight + self.ctx_bias # shape: (-1, C, units)\n",
    "        state_guidance_term = tf.reshape(h_tm1 * self.state_weight + self.state_bias, (-1, 1, self.units)) # shape: (-1, 1, units) \n",
    "        g = KB.tanh(ctx_attention_term + state_guidance_term) # shape: (-1, C, units)\n",
    "        alpha = KB.softmax(tf.reduce_sum(g * self.transform_weight + self.transform_bias, axis=2)) # shape: (-1, C)\n",
    "        alpha = KB.expand_dims(alpha)# shape: (-1, C, 1)\n",
    "        attention_c = tf.reduce_sum(self.ctx_map * alpha, axis=1) # shape: (-1, units)\n",
    "        return super(AttentionRNNCell_Type1, self).call(attention_c, states, training=None)\n",
    "\n",
    "#[AttentionRNNCell_Type1, other cell, ...]\n",
    "class StackedRNNCells_Type1(Layer):\n",
    "    def __init__(self, cells, use_initial_states=False, **kwargs):\n",
    "        self.cells = cells\n",
    "        self.units = 0\n",
    "        self.cell_len = len(cells)\n",
    "        self.use_initial_states = use_initial_states\n",
    "        self.cell_types = []\n",
    "        super(StackedRNNCells_Type1, self).__init__(**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        state_size = []\n",
    "        for cell in self.cells[::-1]:\n",
    "            if hasattr(cell.state_size, '__len__'):\n",
    "                state_size += list(cell.state_size)\n",
    "            else:\n",
    "                state_size.append(cell.state_size)\n",
    "        return tuple(state_size)\n",
    "    \n",
    "    def init_context(self, ctx_block):\n",
    "        c = 0\n",
    "        last_cell = None\n",
    "        for cell in self.cells:\n",
    "            type1 = isinstance(cell, AttentionRNNCell_Type1)\n",
    "            if type1:\n",
    "                self.cell_types.append(\"AttentionRNNCell_Type1\")\n",
    "            else:\n",
    "                self.cell_types.append(\"Normal\")\n",
    "            if hasattr(cell, 'init_context'):\n",
    "                if hasattr(cell, 'use_initial_states'):\n",
    "                    cell.use_initial_states = self.use_initial_states\n",
    "                cell.init_context(ctx_block)\n",
    "            last_cell = cell\n",
    "        self.units = last_cell.units\n",
    "    \n",
    "    def call(self, inputs, states, time_step, **kwargs):\n",
    "        nested_states = []\n",
    "        for cell in self.cells[::-1]:\n",
    "            if hasattr(cell.state_size, '__len__'):\n",
    "                nested_states.append(states[:len(cell.state_size)])\n",
    "                states = states[len(cell.state_size):]\n",
    "            else:\n",
    "                nested_states.append([states[0]])\n",
    "                states = states[1:]\n",
    "        nested_states = nested_states[::-1]\n",
    "\n",
    "        # Call the cells in order and store the returned states.\n",
    "        new_nested_states = []\n",
    "        for i, (cell, states) in enumerate(zip(self.cells, nested_states)):\n",
    "            if self.cell_types[i] == \"AttentionRNNCell_Type1\":\n",
    "                inputs, states = cell.call(inputs, states, time_step, **kwargs)\n",
    "            else:\n",
    "                inputs, states = cell.call(inputs, states, **kwargs)\n",
    "            new_nested_states.append(states)\n",
    "\n",
    "        # Format the new states as a flat list\n",
    "        # in reverse cell order.\n",
    "        states = []\n",
    "        for cell_states in new_nested_states[::-1]:\n",
    "            states += cell_states\n",
    "        return inputs, states\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                cell.build(input_shape)\n",
    "            if hasattr(cell.state_size, '__len__'):\n",
    "                output_dim = cell.state_size[0]\n",
    "            else:\n",
    "                output_dim = cell.state_size\n",
    "        self.output_dim = output_dim\n",
    "        self.built = True\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        weights = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                weights += cell.trainable_weights\n",
    "        return weights\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        weights = []\n",
    "        for cell in self.cells:\n",
    "            if isinstance(cell, Layer):\n",
    "                weights += cell.non_trainable_weights\n",
    "        if not self.trainable:\n",
    "            trainable_weights = []\n",
    "            for cell in self.cells:\n",
    "                if isinstance(cell, Layer):\n",
    "                    trainable_weights += cell.trainable_weights\n",
    "            return trainable_weights + weights\n",
    "        return weights\n",
    "    \n",
    "class AttentionRNN(Layer):\n",
    "    def __init__(self, cell, steps, *args, **kwargs):\n",
    "        super(AttentionRNN, self).__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.steps = steps\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(AttentionRNN, self).build(input_shape)\n",
    "    \n",
    "    def call(self, data_pack):\n",
    "        if len(data_pack) == 1:\n",
    "            data_pack = [data_pack[0], None]\n",
    "        else:\n",
    "            data_pack = [data_pack[0], data_pack[1:]]\n",
    "        context, initial_states = data_pack\n",
    "        # initialize cell\n",
    "        if initial_states is not None:\n",
    "            self.cell.use_initial_states = True\n",
    "        self.cell.init_context(context)\n",
    "        self.units = self.cell.units\n",
    "        if not self.cell.built:\n",
    "            self.cell.build((None, self.units))\n",
    "        # initial states\n",
    "        if initial_states is None:\n",
    "            initial_states = KB.zeros_like(context) # (sample, H, W, C)\n",
    "            initial_states = KB.sum(initial_states, axis=(1, 2, 3)) # (sample, )\n",
    "            initial_states = KB.expand_dims(initial_states)  # (samples, 1)\n",
    "            if hasattr(self.cell.state_size, '__len__'):\n",
    "                initial_states = [KB.tile(initial_states, (1, dim)) for dim in self.cell.state_size]\n",
    "            else: \n",
    "                initial_states = [KB.tile(initial_states, (1, self.units))]\n",
    "        else:\n",
    "            if isinstance(initial_states, tuple):\n",
    "                initial_states = list(initial_states)\n",
    "            elif not isinstance(initial_states, list):\n",
    "                initial_states = [initial_states]\n",
    "        # basic params and functions\n",
    "        time = tf.constant(0, dtype='int32', name='time')\n",
    "        def step_function(states, time_step):\n",
    "            return self.cell.call(None, states, time_step)\n",
    "        def _step(time_step, output_ta, states):\n",
    "            output, states = step_function(states, time_step)\n",
    "            output_ta = output_ta.write(time_step, output)\n",
    "            return time_step + 1, output_ta, states\n",
    "        outputs, _ = step_function(initial_states, time)\n",
    "        output_ta = tensor_array_ops.TensorArray(dtype=outputs.dtype, size=self.steps, tensor_array_name='output_ta')\n",
    "        # while loop\n",
    "        final_outputs = tf.while_loop(lambda time, *_: time < self.steps, _step, [time, output_ta, initial_states], parallel_iterations=32, swap_memory=True)\n",
    "        last_time = final_outputs[0]\n",
    "        output_ta = final_outputs[1]\n",
    "        new_states = final_outputs[2]\n",
    "        # deal with outputs\n",
    "        outputs = output_ta.stack() # time_step, batch_size, units\n",
    "        outputs = tf.transpose(outputs, (1, 0, 2)) # batch_size, time_step, units\n",
    "        outputs = tf.reshape(outputs, (-1, self.cell.units * self.steps)) # batch_size, time_step * units\n",
    "        # deal with last output\n",
    "        last_output = output_ta.read(last_time - 1)\n",
    "        return outputs\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.cell is None or not self.cell.built:\n",
    "            raise Exception(\"Call compute_output_shape after rnn cell are built(after invoking __call__).\")\n",
    "        return (None, self.cell.units * self.steps)\n",
    "    \n",
    "    @property\n",
    "    def trainable_weights(self):\n",
    "        if not self.trainable:\n",
    "            return []\n",
    "        if isinstance(self.cell, Layer):\n",
    "            return self.cell.trainable_weights\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def non_trainable_weights(self):\n",
    "        if isinstance(self.cell, Layer):\n",
    "            if not self.trainable:\n",
    "                return self.cell.weights\n",
    "            return self.cell.non_trainable_weights\n",
    "        return []\n",
    "\n",
    "class GetGRUInputs(Layer):\n",
    "    def call(self, inputs):\n",
    "        H, W, C = [int(i) for i in inputs.shape[1:]] # (4, 4, 512)\n",
    "        units = H * W\n",
    "        gru_inputs = tf.transpose(inputs, (0, 3, 1, 2)) # (-1, C, H, W)\n",
    "        gru_inputs = tf.reshape(gru_inputs, (-1, C, units)) # (-1, time_step, units)\n",
    "        return gru_inputs\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        B, H, W, C = input_shape\n",
    "        return (B, C, H * W)\n",
    "    \n",
    "def getVgg16RecurrentModel():\n",
    "    img_input = Input(shape=X_train.shape[1:], name=\"images\")\n",
    "    angle_input = Input(shape=[1], name=\"angle\")\n",
    "    size_1 = Input(shape=[1], name=\"size_1\")\n",
    "    size_2 = Input(shape=[1], name=\"size_2\")\n",
    "    \n",
    "    # ==================== flow1 ====================\n",
    "    flow1_x = img_input\n",
    "    # -------------------- block1 -------------------\n",
    "    flow1_x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(flow1_x)\n",
    "    # -------------------- block2 -------------------\n",
    "    flow1_x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(flow1_x)\n",
    "    # -------------------- block3 -------------------\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(flow1_x)\n",
    "    # -------------------- block4 -------------------\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(flow1_x)\n",
    "    # -------------------- block5 -------------------\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(flow1_x)\n",
    "    flow1_x = BatchNormalization()(flow1_x)\n",
    "    flow1_x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(flow1_x)\n",
    "    # reduce channel\n",
    "    gru_inputs = Conv2D(16, (1, 1), activation='relu', name='block5_gru_inputs')(flow1_x)\n",
    "    gru_inputs = GetGRUInputs()(gru_inputs)\n",
    "    # encoder\n",
    "    last_output, initial_states, initial_states_rev = Bidirectional(GRU(int(gru_inputs.shape[-1]), return_state=True))(gru_inputs)\n",
    "    initial_states = Add()([initial_states, initial_states_rev])\n",
    "    # decoder\n",
    "    stacked_cells = None\n",
    "    flow1_x = AttentionRNN(StackedRNNCells_Type1([AttentionRNNCell_Type1(), GRUCell(16)]), 10)([flow1_x, initial_states, initial_states])\n",
    "\n",
    "#     flow1_x = Concatenate()([flow1_x, size_1])\n",
    "    predictions = Dense(1, activation='sigmoid', name='predictions')(flow1_x)\n",
    "    model = Model(inputs=img_input, outputs=predictions)\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', None, cache_subdir='models')\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    optimizer = Adam(lr=1e-4)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "getModel = getVgg16RecurrentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images (InputLayer)             (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 75, 75, 64)   1792        images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 75, 75, 64)   256         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 75, 75, 64)   36928       batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 75, 75, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 37, 37, 64)   0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 37, 37, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 37, 37, 128)  512         block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 37, 37, 128)  147584      batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 37, 37, 128)  512         block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 18, 18, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 18, 18, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 18, 18, 256)  1024        block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 18, 18, 256)  590080      batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 18, 18, 256)  1024        block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 18, 18, 256)  590080      batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 18, 18, 256)  1024        block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 9, 9, 256)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 9, 9, 512)    1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 9, 9, 512)    2048        block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 9, 9, 512)    2359808     batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 9, 9, 512)    2048        block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 9, 9, 512)    2359808     batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 9, 9, 512)    2048        block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 9, 9, 512)    2359808     batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 9, 9, 512)    2048        block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 9, 9, 512)    2359808     batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 9, 9, 512)    2048        block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 9, 9, 512)    2359808     batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 9, 9, 512)    2048        block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 4, 4, 512)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block5_gru_inputs (Conv2D)      (None, 4, 4, 16)     8208        block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "get_gru_inputs_15 (GetGRUInputs (None, 16, 16)       0           block5_gru_inputs[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional [(None, 32), (None,  3168        get_gru_inputs_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16)           0           bidirectional_15[0][1]           \n",
      "                                                                 bidirectional_15[0][2]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_rnn_15 (AttentionRNN) (None, 160)          3219        block5_pool[0][0]                \n",
      "                                                                 add_15[0][0]                     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            161         attention_rnn_15[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 14,746,340\n",
      "Trainable params: 14,737,892\n",
      "Non-trainable params: 8,448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "model.summary()\n",
    "plot_model(model, to_file=\"k_scale_net.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.0,\n",
    "                         height_shift_range = 0.0,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.5,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "def get_callbacks(filepath):\n",
    "    es = EarlyStopping('val_loss', patience=20, mode=\"min\")\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-4, mode='min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave, reduce_lr_loss]\n",
    "\n",
    "def flow_x1_x2_y(X1, X2, Y, batch_size, seed):\n",
    "    X1Y = gen.flow(X1, Y, batch_size=batch_size, seed=SEED)\n",
    "    X1X2 = gen.flow(X1, X2, batch_size=batch_size, seed=SEED)\n",
    "    while True:\n",
    "        X1, Y = X1Y.next()\n",
    "        _, X2 = X1X2.next()\n",
    "        yield [X1, X2], Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K=3\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "def Train_StratifiedKFold():\n",
    "    Kfolds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED).split(X_train, Y_train))\n",
    "    for j, (train_idx, test_idx) in enumerate(Kfolds):\n",
    "        print('\\n==========FOLD %s=========='% j)\n",
    "        Xtrain_cv = X_train[train_idx]\n",
    "        Ytrain_cv = Y_train[train_idx]\n",
    "        Xangle_cv = X_angle[train_idx]\n",
    "        Xsize1_cv = X_size_1[train_idx]\n",
    "\n",
    "        Xtrain_val = X_train[test_idx]\n",
    "        Ytrain_val = Y_train[test_idx]\n",
    "        Xangle_val = X_angle[test_idx]\n",
    "        Xsize1_val = X_size_1[test_idx]\n",
    "\n",
    "        Xtrain_input = [X_train, X_size_1]\n",
    "        Xval_input = [Xtrain_val, Xsize1_val]\n",
    "\n",
    "        model_file = 'k_scale_net_%s.hdf5' % j\n",
    "        model = getModel()\n",
    "\n",
    "        steps = np.ceil(len(Xtrain_cv) / batch_size) * 3\n",
    "        model.fit_generator(\n",
    "            flow_x1_x2_y(Xtrain_cv, Xsize1_cv, Ytrain_cv, batch_size=batch_size, seed=SEED), \n",
    "            steps_per_epoch=steps, epochs=epochs, verbose=1, shuffle=True, \n",
    "            callbacks=get_callbacks(model_file), validation_data=(Xval_input, Ytrain_val))\n",
    "\n",
    "        model.load_weights(filepath = model_file)    \n",
    "\n",
    "        score = model.evaluate(Xtrain_input, Y_train, verbose=1)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        score = model.evaluate(Xval_input, Ytrain_val, verbose=1)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "def Train_KFold(j=0):\n",
    "    Xtrain_cv, Xtrain_val, Ytrain_cv, Ytrain_val, Xangle_cv, Xangle_val, Xsize1_cv, Xsize1_val = train_test_split(X_train, Y_train, X_angle, X_size_1, test_size=0.3, shuffle = True, random_state=SEED)\n",
    "    Xtrain_input = X_train # [X_train, X_size_1]\n",
    "    Xval_input = Xtrain_val # [Xtrain_val, Xsize1_val]\n",
    "\n",
    "    model_file = 'k_scale_net_%s.hdf5' % j\n",
    "    model = getModel()\n",
    "\n",
    "    steps = np.ceil(len(Xtrain_cv) / batch_size) * 3\n",
    "    model.fit_generator(\n",
    "        gen.flow(Xtrain_cv, Ytrain_cv, batch_size=batch_size, seed=SEED),# flow_x1_x2_y(Xtrain_cv, Xsize1_cv, Ytrain_cv, batch_size=batch_size, seed=SEED), \n",
    "        steps_per_epoch=steps, epochs=epochs, verbose=1, shuffle=True, \n",
    "        callbacks=get_callbacks(model_file), validation_data=(Xval_input, Ytrain_val))\n",
    "\n",
    "    model.load_weights(filepath = model_file)    \n",
    "\n",
    "    score = model.evaluate(Xtrain_input, Y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])\n",
    "    score = model.evaluate(Xval_input, Ytrain_val, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "108/108 [==============================] - 42s 392ms/step - loss: 0.4877 - acc: 0.7674 - val_loss: 0.3761 - val_acc: 0.8444\n",
      "Epoch 2/150\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.3486 - acc: 0.8562 - val_loss: 0.3459 - val_acc: 0.8548\n",
      "Epoch 3/150\n",
      "108/108 [==============================] - 25s 228ms/step - loss: 0.3346 - acc: 0.8644 - val_loss: 0.3803 - val_acc: 0.8278\n",
      "Epoch 4/150\n",
      "108/108 [==============================] - 25s 232ms/step - loss: 0.2858 - acc: 0.8840 - val_loss: 0.3022 - val_acc: 0.8838\n",
      "Epoch 5/150\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.2406 - acc: 0.9100 - val_loss: 0.2777 - val_acc: 0.8942\n",
      "Epoch 6/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.2788 - acc: 0.8835 - val_loss: 0.2785 - val_acc: 0.8900\n",
      "Epoch 7/150\n",
      "108/108 [==============================] - 26s 239ms/step - loss: 0.2674 - acc: 0.9019 - val_loss: 0.2575 - val_acc: 0.9025\n",
      "Epoch 8/150\n",
      "108/108 [==============================] - 24s 227ms/step - loss: 0.2420 - acc: 0.9002 - val_loss: 0.2641 - val_acc: 0.8817\n",
      "Epoch 9/150\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2653 - acc: 0.8915 - val_loss: 0.2662 - val_acc: 0.8942\n",
      "Epoch 10/150\n",
      "108/108 [==============================] - 25s 234ms/step - loss: 0.2508 - acc: 0.9089 - val_loss: 0.2445 - val_acc: 0.9149\n",
      "Epoch 11/150\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.2218 - acc: 0.9072 - val_loss: 0.2666 - val_acc: 0.9025\n",
      "Epoch 12/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2141 - acc: 0.9167 - val_loss: 0.2756 - val_acc: 0.8921\n",
      "Epoch 13/150\n",
      "108/108 [==============================] - 25s 234ms/step - loss: 0.2298 - acc: 0.9066 - val_loss: 0.2436 - val_acc: 0.9087\n",
      "Epoch 14/150\n",
      "108/108 [==============================] - 25s 231ms/step - loss: 0.2164 - acc: 0.9173 - val_loss: 0.2292 - val_acc: 0.9170\n",
      "Epoch 15/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1963 - acc: 0.9317 - val_loss: 0.2348 - val_acc: 0.9066\n",
      "Epoch 16/150\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.1834 - acc: 0.9297 - val_loss: 0.2677 - val_acc: 0.8880\n",
      "Epoch 17/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2135 - acc: 0.9150 - val_loss: 0.2878 - val_acc: 0.8880\n",
      "Epoch 18/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1741 - acc: 0.9369 - val_loss: 0.2828 - val_acc: 0.8859\n",
      "Epoch 19/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1751 - acc: 0.9286 - val_loss: 0.2581 - val_acc: 0.8963\n",
      "Epoch 20/150\n",
      "108/108 [==============================] - 24s 226ms/step - loss: 0.1671 - acc: 0.9361 - val_loss: 0.2818 - val_acc: 0.8776\n",
      "Epoch 21/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1726 - acc: 0.9375 - val_loss: 0.3337 - val_acc: 0.8320\n",
      "Epoch 22/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.2021 - acc: 0.9205 - val_loss: 0.2388 - val_acc: 0.9129\n",
      "Epoch 23/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.1444 - acc: 0.9462 - val_loss: 0.2470 - val_acc: 0.9046\n",
      "Epoch 24/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.1571 - acc: 0.9364 - val_loss: 0.2656 - val_acc: 0.9046\n",
      "Epoch 25/150\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9293\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "108/108 [==============================] - 25s 236ms/step - loss: 0.1787 - acc: 0.9291 - val_loss: 0.2774 - val_acc: 0.8859\n",
      "Epoch 26/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1567 - acc: 0.9378 - val_loss: 0.2359 - val_acc: 0.9046\n",
      "Epoch 27/150\n",
      "108/108 [==============================] - 25s 233ms/step - loss: 0.1443 - acc: 0.9416 - val_loss: 0.2233 - val_acc: 0.9191\n",
      "Epoch 28/150\n",
      "108/108 [==============================] - 26s 236ms/step - loss: 0.1435 - acc: 0.9456 - val_loss: 0.2172 - val_acc: 0.9274\n",
      "Epoch 29/150\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.1280 - acc: 0.9528 - val_loss: 0.2188 - val_acc: 0.9170\n",
      "Epoch 30/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.1333 - acc: 0.9460 - val_loss: 0.2188 - val_acc: 0.9212\n",
      "Epoch 31/150\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.1248 - acc: 0.9560 - val_loss: 0.2194 - val_acc: 0.9232\n",
      "Epoch 32/150\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.1055 - acc: 0.9635 - val_loss: 0.2181 - val_acc: 0.9253\n",
      "Epoch 33/150\n",
      "108/108 [==============================] - 30s 277ms/step - loss: 0.1022 - acc: 0.9598 - val_loss: 0.2224 - val_acc: 0.9191\n",
      "Epoch 34/150\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.1130 - acc: 0.9540 - val_loss: 0.2275 - val_acc: 0.9232\n",
      "Epoch 35/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.1115 - acc: 0.9552 - val_loss: 0.2230 - val_acc: 0.9149\n",
      "Epoch 36/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.0938 - acc: 0.9685 - val_loss: 0.2212 - val_acc: 0.9191\n",
      "Epoch 37/150\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1237 - acc: 0.9506 - val_loss: 0.2324 - val_acc: 0.9087\n",
      "Epoch 38/150\n",
      "108/108 [==============================] - 24s 224ms/step - loss: 0.0968 - acc: 0.9685 - val_loss: 0.2249 - val_acc: 0.9212\n",
      "Epoch 39/150\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9650\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "108/108 [==============================] - 24s 225ms/step - loss: 0.1010 - acc: 0.9653 - val_loss: 0.2185 - val_acc: 0.9170\n",
      "Epoch 40/150\n",
      "108/108 [==============================] - 24s 222ms/step - loss: 0.0983 - acc: 0.9610 - val_loss: 0.2193 - val_acc: 0.9108\n",
      "Epoch 41/150\n",
      "108/108 [==============================] - 24s 223ms/step - loss: 0.1186 - acc: 0.9549 - val_loss: 0.2223 - val_acc: 0.9170\n",
      "Epoch 42/150\n",
      " 22/108 [=====>........................] - ETA: 18s - loss: 0.0916 - acc: 0.9673"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0c61343b2a82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTrain_KFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-b050eba111cb>\u001b[0m in \u001b[0;36mTrain_KFold\u001b[1;34m(j)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m# flow_x1_x2_y(Xtrain_cv, Xsize1_cv, Ytrain_cv, batch_size=batch_size, seed=SEED),\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         callbacks=get_callbacks(model_file), validation_data=(Xval_input, Ytrain_val))\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Train_KFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_StratifiedKFold():\n",
    "    test_randround = 3\n",
    "    test_pred = 0\n",
    "    for j in range(K):\n",
    "        Xtest_input = [X_test, test_size_1]\n",
    "        model_file = 'k_scale_net_%s.hdf5' % j\n",
    "        model = getModel()\n",
    "        model.load_weights(filepath = model_file)    \n",
    "        for i in range(test_randround):\n",
    "            test_steps = np.ceil(X_test.shape[0] / batch_size)\n",
    "            test_pred += model.predict_generator(flow_x1_x2_y(*Xtest_input, range(X_test.shape[0]), batch_size=batch_size, seed=i), steps=test_steps, verbose=1).reshape(X_test.shape[0])\n",
    "            print(test_pred.shape)\n",
    "    test_pred /= K * test_randround\n",
    "\n",
    "def predict_KFold(j=0, K=1, test_randround=3):\n",
    "    test_pred = 0\n",
    "    for _ in range(K):\n",
    "        Xtest_input = X_test # [X_test, test_size_1]\n",
    "        model_file = 'k_scale_net_%s.hdf5' % j\n",
    "        model = getModel()\n",
    "        model.load_weights(filepath = model_file)    \n",
    "        for i in range(test_randround):\n",
    "            test_steps = np.ceil(X_test.shape[0] / batch_size)\n",
    "            test_pred += model.predict_generator(\n",
    "                gen.flow(Xtest_input, range(X_test.shape[0]), batch_size=batch_size, seed=i), # flow_x1_x2_y(*Xtest_input, range(X_test.shape[0]), batch_size=batch_size, seed=i), \n",
    "                steps=test_steps, verbose=1).reshape(X_test.shape[0])\n",
    "            print(test_pred.shape)\n",
    "    test_pred /= K * test_randround\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = predict_KFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            8424\n",
      "is_iceberg    8424\n",
      "dtype: int64 8424\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': test_pred})\n",
    "print(submission.count(), X_test.shape[0])\n",
    "\n",
    "submission.to_csv('submission-k-scale-net.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
